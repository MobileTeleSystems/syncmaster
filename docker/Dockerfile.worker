ARG PYTHON_VERSION=3.13
FROM python:$PYTHON_VERSION-slim-bookworm AS base

RUN apt-get update && apt-get install -y --no-install-recommends \
        tini \
        openjdk-17-jdk-headless \
        # required for HDFS/Hive with Kerberos enabled
        krb5-user \
    && rm -rf /var/lib/apt/lists/* /var/cache/*

WORKDIR /app
ENV PYTHONPATH=/app \
    PATH="/app/.venv/bin:$PATH" \
    PYTHONUNBUFFERED=1

COPY ./docker/entrypoint_worker.sh /app/entrypoint.sh
RUN chmod +x /app/entrypoint.sh
ENTRYPOINT ["/app/entrypoint.sh"]


FROM base AS builder

RUN apt-get update && apt-get install -y --no-install-recommends \
        autoconf \
        gcc \
        make \
        # required to build gssapi from sources
        libkrb5-dev \
    && rm -rf /var/lib/apt/lists/* /var/cache/*

COPY --from=ghcr.io/astral-sh/uv:latest /uv /usr/bin/uv

COPY ./pyproject.toml ./uv.lock ./
RUN --mount=type=cache,target=/root/.cache/uv \
    uv sync \
        --frozen \
        --no-install-project \
        --extra "worker" \
        --extra "kerberos" \
        --compile-bytecode


FROM builder AS ivy2_packages

RUN --mount=type=bind,source=./syncmaster/worker/ivy2.py,target=/app/syncmaster/worker/ivy2.py \
    --mount=type=bind,source=./docker/download_ivy2_packages.py,target=/app/docker/download_ivy2_packages.py \
    --mount=type=cache,target=/root/.ivy2/ \
    # Try to download all dependencies at once.
    # If multiple packages depends on the same transitive dependency, Spark uses maximum version of this dependency.
    python /app/docker/download_ivy2_packages.py all && \
    # Then try to download specific connectors to fetch exact dependency version specified within connector.
    # Yes, this is slow, but otherwise using worker without internet access will fail, unless custom ivysettings.xml is used
    python /app/docker/download_ivy2_packages.py s3 && \
    python /app/docker/download_ivy2_packages.py hdfs && \
    python /app/docker/download_ivy2_packages.py clickhouse && \
    python /app/docker/download_ivy2_packages.py iceberg && \
    python /app/docker/download_ivy2_packages.py postgres && \
    python /app/docker/download_ivy2_packages.py oracle && \
    python /app/docker/download_ivy2_packages.py mssql && \
    python /app/docker/download_ivy2_packages.py mysql && \
    mkdir -p /home/syncmaster/.ivy2/  && \
    cp --recursive /root/.ivy2/* /home/syncmaster/.ivy2/
    # if someone uses custom worker image, they should download jars on their own


FROM base AS prod

# Do not run production as root, to improve security.
# Also user does not own anything inside the image, including venv and source code.
RUN useradd syncmaster && \
    mkdir -p /home/syncmaster /home/syncmaster/.ivy2 && \
    chown -R syncmaster:syncmaster /home/syncmaster

COPY --from=builder /app/.venv/ /app/.venv/
# custom Spark session function may download different jars, so syncmaster have to own them
COPY --from=ivy2_packages --chown=syncmaster:syncmaster /home/syncmaster/.ivy2/ /home/syncmaster/.ivy2/
# If someone needs to use worker image with root user, use the same jars
RUN mkdir -p /root && \
    ln -s /home/syncmaster/.ivy2 /root/.ivy2

COPY ./syncmaster/ /app/syncmaster/
RUN python -m compileall syncmaster
USER syncmaster


FROM ivy2_packages AS test

RUN mkdir -p /root && \
    ln -s /home/syncmaster/.ivy2 /root/.ivy2

RUN --mount=type=cache,target=/root/.cache/uv \
    uv sync \
        --frozen \
        --no-install-project \
        # CI runs tests in the worker container,
        # so we need server & scheduler dependencies too
        --all-extras \
        --group "test" \
        --compile-bytecode

ENV SYNCMASTER__WORKER__CREATE_SPARK_SESSION_FUNCTION=tests.spark.get_worker_spark_session

# Collect coverage from worker
RUN sed -i 's/python -m/coverage run -m/g' /app/entrypoint.sh

# Replace kinit binary with dummy, to skip Kerberos interaction in tests
RUN mkdir -p /app/.local/bin && \
    echo "#!/bin/bash" > /app/.local/bin/kinit \
    && chmod +x /app/.local/bin/kinit
ENV PATH="/app/.local/bin:$PATH"
